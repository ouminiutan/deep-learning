<style>
table
{
    margin: auto;
}
</style>

## 实验与改进

### baseline

使用learning rate=1e-4，batch size=1，steps=40000，交叉熵损失函数进行训练，得到的模型作为baseline。模型预测效果如下表，结果表明baseline的预测效果不如原始论文所述。

| | | baseline |
| :-------: | :-------: | :-------: |
| **overall_accu** | | 0.858 |
| **mean_accu(room)** | | 0.595 |
| **mean_accu(room+boundary)** | | 0.648 |
| **class_accu** | background | 0.987 |
| | closet | 0.409 |
| | bathroom & etc | 0.659 |
| | living room & etc | 0.798 |
| | bedrooom | 0.573 |
| | hall | 0.585 |
| | balcony | 0.160 |
| | door and window | 0.707 |
| | wall | 0.956 |

在baseline的基础上，我们尝试对部分训练参数和原始网络结构进行了改进，并对比了改进前后的预测效果。

### batch size的影响

在baseline的基础上，修改batch size=2/4(更大的batch size受限于我们的显存大小)，进行模型训练，以此探究batch size对模型训练效果的影响。预测结果如下表。

| | | baseline | batch size=2 | batch size=4 |
| :-------: | :-------: | :-------: | :-------: | :-------: |
| **overall_accu** | | `0.858` | 0.831 | 0.854 | 
| **mean_accu(room)** | | `0.595` | 0.557 | 0.592 | 
| **mean_accu(room+boundary)** | | `0.648` | 0.613 | 0.639 |
| **class_accu** | background | `0.987` | 0.978 | 0.978 |
| | closet | 0.409 | `0.445` | 0.436 |
| | bathroom & etc | `0.659` | 0.635 | 0.643 
| | living room & etc | 0.798 | 0.712 | `0.805` |
| | bedrooom | `0.573` | 0.498 | 0.559 | 
| | hall | `0.585`| 0.564 | 0.569 |
| | balcony | `0.160` | 0.064 | 0.155 |
| | door and window | `0.707` | 0.671 | 0.649 |
| | wall | `0.956` | 0.948 | 0.953 |

batch size增加为2时，预测准确率有较明显的下降。batch size增加为4时，整体预测准确率相比baseline无明显下降。

batch size从1增加为2的性能损失可能源自于训练数据较少，此时更小的batch size可以更充分地利用每一条训练数据。

### 增加学习率衰减策略

原论文训练时使用Adam优化器，能够动态地调整更新步长，但未使用学习率衰减策略。

尽管使用Adam优化器的情况下学习率衰减似乎不是必需的，某些资料还是表明同时使用Adam优化器以及学习率衰减策略能够一定程度上提升模型训练效果，因此我们增加了学习率指数衰减策略，衰减系数=0.98。模型预测结果如下表。

| | | baseline | 学习率指数衰减 |
| :-------: | :-------: | :-------: | :-------: |
| **overall_accu** | | `0.858` | 0.834 |
| **mean_accu(room)** | | `0.595` | 0.567 |
| **mean_accu(room+boundary)** | | `0.648` | 0.618 |
| **class_accu** | background | `0.987` | 0.979 |
| | closet | `0.409` | 0.305 |
| | bathroom & etc | `0.659` | 0.505 |
| | living room & etc | `0.798` | 0.765 |
| | bedrooom | `0.573` | 0.509 | 
| | hall | `0.585` | 0.410
| | balcony | 0.160 | `0.493` |
| | door and window | `0.707` | 0.653 |
| | wall | `0.956` | 0.944 |

使用学习率衰减策略后，没有取得预期中的预测准确度提升，反而整体预测准确度有明显下降，但对特定类型balcony的预测准确度提升明显。

### 使用balanced entropy loss

相比普通的交叉熵损失，balanced entropy loss增加了对所属某一类的样本的数量的考虑：样本越少，权重相对更大。使用balanced entropy loss训练得到的模型预测效果如下表。

| | | baseline | balanced entropy loss |
| :-------: | :-------: | :-------: | :-------: |
| **overall_accu** | | `0.858` | 0.831 |
| **mean_accu(room)** | | `0.595` | 0.537 |
| **mean_accu(room+boundary)** | | `0.648` | 0.598 |
| **class_accu** | background | `0.987` | 0.981 |
| | closet | 0.409 | `0.447` |
| | bathroom & etc | `0.659` | 0.471 |
| | living room & etc | `0.798` | 0.694 |
| | bedrooom | 0.573 | `0.574` | 
| | hall | `0.585` | 0.468 |
| | balcony | `0.160` | 0.125 |
| | door and window | `0.707` | 0.676 |
| | wall | `0.956` | 0.944 |

使用balanced entropy loss后预测准确度存在较明显的下降，其实际作用值得商榷。

### 修改encoder为VGG19

原论文使用的encoder模型为VGG16，这里将其修改为VGG19。VGG19相比VGG16变化不大，只是增加了三个卷积层。模型预测结果如下表。

| | | baseline | 使用VGG19 |
| :-------: | :-------: | :-------: | :-------: |
| **overall_accu** | | 0.858 | `0.861` |
| **mean_accu(room)** | | 0.595 | `0.604` |
| **mean_accu(room+boundary)** | | 0.648 | `0.651` |
| **class_accu** | background | `0.987` | 0.979 |
| | closet | `0.409` | 0.403 |
| | bathroom & etc | 0.659 | `0.669` |
| | living room & etc | `0.798` | 0.779 |
| | bedrooom | 0.573 | `0.644` | 
| | hall | `0.585` | 0.578
| | balcony | 0.160 | `0.206` |
| | door and window | `0.707` | 0.672 |
| | wall | 0.956 | `0.957` |

修改encoder为VGG19后，整体预测准确率有些许提升。

### 修改spatial contextual module

论文对room boundary和room type分别使用两个不同的VGG decoder，同时在room type decoder的每一层加入了来自room boundary decoder对应层的特征。

但注意到，两个decoder层之间不应该是一一对应的，来自room boundary decoder高层的特征同样有助于room type的预测，因此我们采用了类似全连接的思路，将单一的
contextual module修改为multi contextual module。

<center>multi contextual module</center>

!["图片显示失败"](https://github.com/ouminiutan/deep-learning/blob/master/multi-contextual.png?raw=true "multi contextual module")

模型预测效果如下表。

| | | baseline | multi-contextual |
| :-------: | :-------: | :-------: | :-------: |
| **overall_accu** | | 0.858 | `0.868` |
| **mean_accu(room)** | | 0.595 | `0.636` |
| **mean_accu(room+boundary)** | | 0.648 | `0.677` |
| **class_accu** | background | `0.987` | 0.978 |
| | closet | 0.409 | `0.466` |
| | bathroom & etc | `0.659` | 0.623 |
| | living room & etc | 0.798 | `0.826` |
| | bedrooom | 0.573 | `0.629` | 
| | hall | 0.585 | `0.597` |
| | balcony | 0.160 | `0.331` |
| | door and window | `0.707` | 0.688 |
| | wall | 0.956 | `0.959` |'

使用修改后的contextual module，模型预测准确率有一定程度提高。

